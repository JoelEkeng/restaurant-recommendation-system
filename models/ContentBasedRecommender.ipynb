<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_business_data():\n",
    "    business = pd.read_csv(\"data/business.csv\")\n",
    "    review = pd.read_csv(\"data/review.csv\")\n",
    "    data = pd.merge(left=review, right=business, how='left', on='business_id')\n",
    "    return data\n",
    "\n",
    "data = load_business_data()\n",
    "\n",
    "data.rename(columns={'stars_x':'rating', 'stars_y':'b/s_rating'}, inplace=True)\n",
    "\n",
    "data.fillna({'address': 'Not-Available', \n",
    "            'attributes': 'Not-Available', \n",
    "            'categories': 'Not-Available', \n",
    "            'hours': 'Not-Available'}, inplace=True)\n",
    "\n",
    "data['location']=data[['city','state','address']]\\\n",
    "            .apply( lambda x: f\"State:{x['state']}, City:{x['city']}, Address:{x['address']} \", axis=1)\n",
    "\n",
    "# then we drop the combined columns\n",
    "data.drop(columns=['state', 'city','address'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only the unique user ids as a dataframe\n",
    "ids=data[['user_id']].drop_duplicates('user_id').reset_index(drop=True).copy()\n",
    "\n",
    "ids=ids.reset_index()\n",
    "\n",
    "# merging the ids dataframe with our original dataframe using the user id column as primary key\n",
    "# renaming the index column to represent the user ids\n",
    "data=pd.merge(data,ids, how='left', on='user_id').drop('user_id', axis=1).rename(columns={'index':'user_id'})\n",
    "\n",
    "# writting a function to order the user ids to start from 1 instead of '0'\n",
    "def add(x):\n",
    "    \"\"\" adds 1 to the existing user id\"\"\"\n",
    "    y=x+1\n",
    "    return y\n",
    "data.user_id=data.user_id.apply(add ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                          name  \\\n",
      "0  XQfwVwDr-v0ZS3_CbbE5Xw  Turning Point of North Wales   \n",
      "2  kxX2SOes4o-D3ZQBkiMRfA                         Zaika   \n",
      "4  04UD14gamNjLY0IDYVhHJg                      Dmitri's   \n",
      "5  LHSTtnW3YHCeUkRDGyJOyw               Fries Rebellion   \n",
      "9  RZtGWDLCAtuipwaZ-UfjmQ                     LaScala's   \n",
      "\n",
      "                                          categories  \\\n",
      "0  [Restaurants, Breakfast & Brunch, Food, Juice ...   \n",
      "2            [Halal, Pakistani, Restaurants, Indian]   \n",
      "4       [Mediterranean, Restaurants, Seafood, Greek]   \n",
      "5  [Beer Bar, Bars, American (New), Gastropubs, R...   \n",
      "9               [Pizza, Restaurants, Italian, Salad]   \n",
      "\n",
      "                                          attributes  \\\n",
      "0  {'NoiseLevel': 'u'average'', 'HasTV': 'False',...   \n",
      "2  {'Caters': 'True', 'Ambience': '{'romantic': F...   \n",
      "4  {'BusinessParking': '{'garage': False, 'street...   \n",
      "5  {'RestaurantsAttire': ''casual'', 'Ambience': ...   \n",
      "9  {'RestaurantsReservations': 'True', 'BYOBCorka...   \n",
      "\n",
      "                                            location  rating  \\\n",
      "0  State:PA, City:North Wales, Address:1460 Bethl...     3.0   \n",
      "2  State:PA, City:Philadelphia, Address:2481 Gran...     5.0   \n",
      "4  State:PA, City:Philadelphia, Address:795 S 3rd...     1.0   \n",
      "5  State:PA, City:Quakertown, Address:1441 S West...     5.0   \n",
      "9  State:PA, City:Philadelphia, Address:615 Chest...     4.0   \n",
      "\n",
      "                  user_id                                               text  \\\n",
      "0  mh_-eMZ6K5RLWhZyISBhwA  If you decide to eat here, just be aware it is...   \n",
      "2  _7bHUi9Uuf5__HHc_Q8guQ  Wow!  Yummy, different,  delicious.   Our favo...   \n",
      "4  eUta8W_HdHMXPzLBBZhL1A  I am a long term frequent customer of this est...   \n",
      "5  yfFzsLmaWF2d4Sr0UNbBgg  Amazingly amazing wings and homemade bleu chee...   \n",
      "9  smOvOajNG0lS4Pq7d8g4JQ  Good food--loved the gnocchi with marinara\\nth...   \n",
      "\n",
      "   price_range  \n",
      "0            2  \n",
      "2            2  \n",
      "4            2  \n",
      "5            2  \n",
      "9            2  \n"
     ]
    }
   ],
   "source": [
    "# selecting only the restaurants\n",
    "data=data.loc[ data.categories.str.contains('Restaurants')].copy().reset_index(drop=True)\n",
    "data.shape\n",
    "\n",
    "# droping irrelevant columns\n",
    "cols=['review_id', 'useful','postal_code','funny', 'cool', 'is_open', 'date']\n",
    "data.drop(columns=cols, axis=1, inplace=True)\n",
    "\n",
    "# Ensure we have the necessary columns\n",
    "data = data[['business_id', 'name', 'categories', 'attributes', 'location', 'rating', 'user_id', 'text']]\n",
    "def safe_literal_eval(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "data['categories'] = data['categories'].apply(lambda x: [] if x == 'Not-Available' else x.split(', '))\n",
    "data['attributes'] = data['attributes'].apply(safe_literal_eval)\n",
    "\n",
    "# Create a feature for price range (from attributes)\n",
    "data['price_range'] = data['attributes'].apply(lambda x: int(x.get('RestaurantsPriceRange2', 0)) if isinstance(x, dict) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                          name  \\\n",
      "0  XQfwVwDr-v0ZS3_CbbE5Xw  Turning Point of North Wales   \n",
      "2  kxX2SOes4o-D3ZQBkiMRfA                         Zaika   \n",
      "4  04UD14gamNjLY0IDYVhHJg                      Dmitri's   \n",
      "5  LHSTtnW3YHCeUkRDGyJOyw               Fries Rebellion   \n",
      "9  RZtGWDLCAtuipwaZ-UfjmQ                     LaScala's   \n",
      "\n",
      "                                          categories  \\\n",
      "0  [Restaurants, Breakfast & Brunch, Food, Juice ...   \n",
      "2            [Halal, Pakistani, Restaurants, Indian]   \n",
      "4       [Mediterranean, Restaurants, Seafood, Greek]   \n",
      "5  [Beer Bar, Bars, American (New), Gastropubs, R...   \n",
      "9               [Pizza, Restaurants, Italian, Salad]   \n",
      "\n",
      "                                          attributes  \\\n",
      "0  {'NoiseLevel': 'u'average'', 'HasTV': 'False',...   \n",
      "2  {'Caters': 'True', 'Ambience': '{'romantic': F...   \n",
      "4  {'BusinessParking': '{'garage': False, 'street...   \n",
      "5  {'RestaurantsAttire': ''casual'', 'Ambience': ...   \n",
      "9  {'RestaurantsReservations': 'True', 'BYOBCorka...   \n",
      "\n",
      "                                            location  rating  \\\n",
      "0  State:PA, City:North Wales, Address:1460 Bethl...     3.0   \n",
      "2  State:PA, City:Philadelphia, Address:2481 Gran...     5.0   \n",
      "4  State:PA, City:Philadelphia, Address:795 S 3rd...     1.0   \n",
      "5  State:PA, City:Quakertown, Address:1441 S West...     5.0   \n",
      "9  State:PA, City:Philadelphia, Address:615 Chest...     4.0   \n",
      "\n",
      "                  user_id                                               text  \\\n",
      "0  mh_-eMZ6K5RLWhZyISBhwA  If you decide to eat here, just be aware it is...   \n",
      "2  _7bHUi9Uuf5__HHc_Q8guQ  Wow!  Yummy, different,  delicious.   Our favo...   \n",
      "4  eUta8W_HdHMXPzLBBZhL1A  I am a long term frequent customer of this est...   \n",
      "5  yfFzsLmaWF2d4Sr0UNbBgg  Amazingly amazing wings and homemade bleu chee...   \n",
      "9  smOvOajNG0lS4Pq7d8g4JQ  Good food--loved the gnocchi with marinara\\nth...   \n",
      "\n",
      "   price_range  \n",
      "0            2  \n",
      "2            2  \n",
      "4            2  \n",
      "5            2  \n",
      "9            2  \n"
     ]
    }
   ],
   "source": [
    "# Use streamlit to display to ask user to enter location\n",
    "\n",
    "# Filter businesses located in Pennsylvania (PA)\n",
    "pa_businesses = data[data['location'].str.contains('State:PA')]\n",
    "\n",
    "# Now pa_businesses contains only the businesses from PA\n",
    "print(pa_businesses.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for business ID 04UD14gamNjLY0IDYVhHJg\n",
      "24407                     Stella Sera\n",
      "20692                  Pizzeria Vetri\n",
      "12436            Nannie Francos Pizza\n",
      "26445                       LaScala's\n",
      "6058              Giovanni's Pizzeria\n",
      "16250                       LaScala's\n",
      "31273                    Slices Pizza\n",
      "37238    Maria's Ristorante on Summit\n",
      "1932                      Stella Sera\n",
      "39045             Francos Tomato Pies\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a TF-IDF vectorizer to convert text data into numerical vectors\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Combine relevant text features (categories and text) for content-based filtering\n",
    "pa_businesses.loc[:, 'combined_features'] = pa_businesses['categories'].astype(str) + ' ' + pa_businesses['text']\n",
    "\n",
    "\n",
    "# Fit and transform the combined features\n",
    "tfidf_matrix = tfidf.fit_transform(pa_businesses['combined_features'])\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to get recommendations based on business ID\n",
    "def get_recommendations(business_id, cosine_sim=cosine_sim):\n",
    "    # Get the index of the business\n",
    "    \"\"\" idx = pa_businesses[pa_businesses['business_id'] == business_id].index[0] \"\"\"\n",
    "\n",
    "    idx = pa_businesses[pa_businesses['location'] == pa_businesses[pa_businesses['business_id']== business_id]['location'].values[0]].index[0]\n",
    "\n",
    "    # Get the pairwise similarity scores\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the businesses based on similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar businesses\n",
    "    sim_scores = sim_scores[1:11]  # Exclude the business itself\n",
    "\n",
    "    # Get the business indices\n",
    "    business_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar businesses\n",
    "    return pa_businesses['name'].iloc[business_indices]\n",
    "\n",
    "# Example usage\n",
    "business_id_to_recommend = pa_businesses['business_id'].iloc[2]\n",
    "recommendations = get_recommendations(business_id_to_recommend)\n",
    "print(f\"Recommendations for business ID {business_id_to_recommend}\")\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eengj\\AppData\\Local\\Temp\\ipykernel_10804\\2466059450.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pa_businesses['normalized_stars'] = scaler.fit_transform(pa_businesses[['rating']])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['b/s_rating'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[0;32m      3\u001b[0m pa_businesses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_stars\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(pa_businesses[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m----> 4\u001b[0m pa_businesses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_reviews\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mpa_businesses\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb/s_rating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate the weighted score\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Weight the cosine similarity\u001b[39;00m\n\u001b[0;32m     10\u001b[0m weighted_sim \u001b[38;5;241m=\u001b[39m cosine_sim \u001b[38;5;241m*\u001b[39m (pa_businesses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_stars\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[:, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m pa_businesses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_reviews\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[:, \u001b[38;5;28;01mNone\u001b[39;00m])\n",
      "File \u001b[1;32mc:\\Users\\eengj\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\eengj\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eengj\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['b/s_rating'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Normalize the ratings\n",
    "scaler = MinMaxScaler()\n",
    "pa_businesses['normalized_stars'] = scaler.fit_transform(pa_businesses[['rating']])\n",
    "pa_businesses['normalized_reviews'] = scaler.fit_transform(pa_businesses[['b/s_rating']])\n",
    "\n",
    "\n",
    "# Calculate the weighted score\n",
    "\n",
    "# Weight the cosine similarity\n",
    "weighted_sim = cosine_sim * (pa_businesses['normalized_stars'].values[:, None] * pa_businesses['normalized_reviews'].values[:, None])\n",
    "\n",
    "\n",
    "# Update indices mapping\n",
    "indices = pd.Series(pa_businesses.index, index=pa_businesses['name']).drop_duplicates()\n",
    "\n",
    "## Function to get weighted recommendations\n",
    "def get_weighted_recommendations(name, weighted_sim=weighted_sim):\n",
    "    try:\n",
    "        idx = indices[name]\n",
    "        sim_scores = list(enumerate(weighted_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:11]  # Top 10 recommendations\n",
    "        business_indices = [i[0] for i in sim_scores]\n",
    "        return pa_businesses['name'].iloc[business_indices].tolist()\n",
    "    except KeyError:\n",
    "        return [f\"Restaurant '{name}' not found.\"]\n",
    "\n",
    "# User Input and Display Recommendations\n",
    "name = st.text_input(\"Enter a restaurant name for recommendations:\")\n",
    "\n",
    "if st.button(\"Get Recommendations\"):\n",
    "    if name:\n",
    "        recommendations = get_weighted_recommendations(name)\n",
    "        st.write(\"Here are the top recommendations:\")\n",
    "        for rec in recommendations:\n",
    "            st.write(f\"- {rec}\")\n",
    "    else:\n",
    "        st.warning(\"Please enter a restaurant name.\")\n",
    "\n",
    "\n",
    "def evaluate_recommendations(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Mean Average Precision (MAP)\n",
    "def mean_average_precision(recommended, relevant):\n",
    "    ap = 0.0\n",
    "    hits = 0\n",
    "    for i, item in enumerate(recommended):\n",
    "        if item in relevant:\n",
    "            hits += 1\n",
    "            ap += hits / (i + 1)\n",
    "    return ap / len(relevant)\n",
    "\n",
    "# Example evaluation (assuming you have ground truth data)\n",
    "y_true = [1, 0, 1, 0, 1]  # Replace with actual relevant items\n",
    "y_pred = [1, 1, 0, 0, 1]  # Replace with actual recommended items\n",
    "\n",
    "precision, recall, f1 = evaluate_recommendations(y_true, y_pred)\n",
    "\n",
    "# Display accuracy results in Streamlit\n",
    "st.write(\"Evaluation Metrics:\")\n",
    "accuracyresult = pd.DataFrame({\n",
    "    'Precision': [precision], \n",
    "    'Recall': [recall], \n",
    "    'F1 Score': [f1]\n",
    "})\n",
    "st.dataframe(accuracyresult)\n",
    "\n",
    "st.write(get_weighted_recommendations('Restaurant Name'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
=======
version https://git-lfs.github.com/spec/v1
oid sha256:4e27b5be8450013a535abedd7cf073846f07a4ac945ec5e7540672b3cd6bbf4b
size 20648
>>>>>>> 418cf632692cb2d9bdcd6d8f5346128c404876c6
